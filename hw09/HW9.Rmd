---
title: "HW09"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 



1. Get HTML
Get the content of the page into R.
```{r}
library(xml2)
library(httr)
library(rvest)

url <- "https://en.wikipedia.org/wiki/Mitch_McConnell"
wiki <- read_html(url)
wiki

```

2. Get the info box
On the right side of the page is a box of structured content, called an info box. Wikipedia has many types of such info boxes to provide content comparably for a group of articles of the same class (e.g. the Members of the U.S. senate, Fortune 500 companies, Crime Syndicates etc.)
a) Find the CSS class of the infobox.
b) Extract the part of the HTML document that contains the infobox using the CSS information.



3. Make a data frame
a) Parse the infobox table HTML you obtained above into a data frame.

```{r}
# a) table
html_name(html_nodes(wiki, css = ".vcard"))


# b) 
#html_text(html_node(wiki, css = ".vcard"))
library(tidyverse)
table <- wiki %>%
html_nodes("table.vcard") %>%
html_table( fill=TRUE)

#View (table)
table <- table[[1]]
full_name <- colnames(table)[1]
colnames(table) <- c('X1', 'X2')

upper <- table[3:42, 1:2]

```

b) Name the columns of the table you obtain key and value. So, in the example for Mitch McConnell, "Deputy" would be the key, and the content information (i.e. the value) is "John Cornyn".

```{r}
upper <- tibble::rowid_to_column(upper)
table2 <- upper %>%
  spread(key=X1, value=X2, fill=NA )



#part1
table2[1,5] = table2[3,5]
table2[1,7] = table2[4,7]
table2[1,18] = table2[5,18]

table2 <- table2[-c(3,4,5),]

#part2
table2[2,7] = table2[5,7]
table2[2,13] = table2[4,13]
table2[2,23] = table2[7,23]
table2[2,18] = table2[6,18]
table2[2,22] = table2[3,22]

table2 <- table2[-c(5,4,7,6,3),]

#part3
table2[3,4] = table2[5,4]
table2[3,7] = table2[6,7]
table2[3,14] = table2[4,14]
table2[3,18] = table2[7,18]
table2 <- table2[-c(5,6,4,7),]


#part4
table2[4,3] = table2[11,3]
table2[4,14] = table2[10,14]
table2[4,18] = table2[12,18]
table2[4,24] = table2[9,24]

table2 <- table2[-c(11,10,12,9),]


#part5
table2[5,6] = table2[9,6]
table2[5,10] = table2[10,10]
table2[5,18] = table2[11,18]
table2[5,23] = table2[12,23]

table2 <- table2[-c(9,10,11,12),]


#part6
table2[6,11] = table2[9,11]
table2[6,18] = table2[10,18]
table2[6,23] = table2[11,23]
table2 <- table2[-c(9,10,11),]


#part7
table2[7,9] = table2[10,9]
table2[7,15] = table2[9,15]
table2[7,18] = table2[11,18]
table2[7,23] = table2[12,23]
table2 <- table2[-c(10,11,9, 12),]

#part8
table2[8,2] = table2[9,2]
table2[8,8] = table2[10,8]
table2[8,18] = table2[12,18]
table2[8,19] = table2[11,19]
table2[8,23] = table2[13,23]

table2 <- table2[-c(9,11,13, 10,12),]

table2
```

c) Filter the data frame (and rename variables if necessary) to the "Full name", "Political Party", and "Children". Use this selection of variables for all subsequent questions.

You should now have the following data frame to work with:
```{r}
personal_table <- table %>%
  filter(X1== 'Children'|X1=='Political party') 

a <- c('Full name', full_name)
personal_table <- rbind (a, personal_table)
```



```{r, eval=FALSE}
#use tidyverse to spread the dataframe


View (upper)

#part1
part1 <- upper[1:5, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )


View (part1)
part1[1,2] = part1[3,2]
part1[1,3] = part1[4,3]
part1[1,4] = part1[2,4]
part1[1,5] = part1[5,5]
part1[1,6] = part1[1,6]
part1 <-  na.omit(part1)

#part2
part2 <- upper[6:10, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )

View (part2)
part2[1,2] = part2[3,2]
part2[1,3] = part2[2,3]
part2[1,4] = part2[4,4]
part2[1,5] = part2[1,5]
part2[1,6] = part2[5,6]

part2 <-  na.omit(part2)


#part3
part3 <- upper[11:15, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )

View (part3)
part3[1,2] = part3[3,2]
part3[1,3] = part3[4,3]
part3[1,4] = part3[2,4]
part3[1,5] = part3[1,5]
part3[1,6] = part3[5,6]

part3 <-  na.omit(part3)


#part 4
part4 <- upper[21:24, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )

View (part4)
part4[1,2] = part4[3,2]
part4[1,3] = part4[2,3]
part4[1,4] = part4[4,4]
part4[1,5] = part4[1,5]


part4 <-  na.omit(part4)



#part 5
part5 <- upper[25:28, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )


View (part5)
part5[1,2] = part5[1,2]
part5[1,3] = part5[2,3]
part5[1,4] = part5[3,4]
part5[1,5] = part5[4,5]


part5 <-  na.omit(part5)

#part 6
part6 <- upper[29:31, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )

View (part6)
part6[1,2] = part6[1,2]
part6[1,3] = part6[2,3]
part6[1,4] = part6[3,4]

part6 <-  na.omit(part6)

#part 7
part7 <- upper[32:35, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )


View (part7)
part7[1,2] = part7[2,2]
part7[1,3] = part7[1,3]
part7[1,4] = part7[3,4]
part7[1,5] = part7[4,5]

part7 <-  na.omit(part7)


#part 8
part8 <- upper[36:40, 1:3] %>%
  spread(key=X1, value=X2, fill=NA )

View (part8)
part8[1,2] = part8[1,2]
part8[1,3] = part8[2,3]
part8[1,4] = part8[4,4]
part8[1,5] = part8[3,5]
part8[1,6] = part8[5,6]

part8 <-  na.omit(part8)


rbind (part1, part2)
```


4. Make a function
a) Use the code above to make a function called get_wiki_info that uses a single input url (a Wikipedia URL) and outputs the data frame of the format above. There is no need to account for exceptions (e.g. no info box on the page; page does not exist etc.) - we will only use members of the U.S. Senate for this exercise.

```{r}
get_wiki_info <- function (url) {
 
  #extract from html
  url <- read_html (url)
  table <- url %>%
  html_nodes("table.vcard") %>%
  html_table( fill=TRUE)

  #unnested talbe
  table <- table[[1]]
  
  #get the senator's full name
  full_name <- colnames(table)[1]
  
  #rename the column of the table
  colnames(table) <- c('X1', 'X2')
  
  
  #get the df
  personal_table <- table 
  
  #add a condition of no children 
  children <- 'Children'
  #turn list to vec for later check
  list_to_vec <- unlist(table['X1'])
  if (any (children %in% list_to_vec)){
    
    personal_table <- filter(table, X1== 'Children'|X1=='Political party') 
  
    #add full name into the df
    a <- c('Full name', full_name)
    personal_table <- rbind (a, personal_table)
  
    return(personal_table)
  } else {
    personal_table <- filter(table, X1=='Political party') 
    
    #add a children NA row
    b <- c('Children', NA)
    personal_table <- rbind (b, personal_table)
    
    #add full name into the df
    a <- c('Full name', full_name)
    personal_table <- rbind (a, personal_table)
    return (personal_table)
  
  }
  
}

get_wiki_info("https://en.wikipedia.org/wiki/Mitch_McConnell")



```



b) Show how your function works on the following two URLs:

https://en.wikipedia.org/wiki/Tammy_Duckworth
https://en.wikipedia.org/wiki/Susan_Collins
Depending on your previous function, you may receive an error message because Susan Collins has no entry for Children. Fix your function so that NA is recorded in such instances.

```{r}
print (get_wiki_info("https://en.wikipedia.org/wiki/Tammy_Duckworth"))
print (get_wiki_info("https://en.wikipedia.org/wiki/Susan_Collins"))

```


5. Get all senators' pages

a) Import the site and obtain a vector with the URLs for the Wikipedia sites of all 100 members of congress (hint: the function xml_attr is one option). Note, this should only include the URLs and remove all other content.


```{r}
senator <- read_html("https://en.wikipedia.org/wiki/List_of_current_United_States_senators")
#instantiate empty url
url <- c()

for (i in 2:101) {
    #extract from the nodes
    table_url_node <- html_node(x = senator, xpath = 
                                  paste0('//*[@id="senators"]/tbody/tr[', as.character(i), 
                                         ']/th/span/span/span/a'))

    #extract url from attributes
    url[i] <- xml_attrs(table_url_node)['href']
}

#formulating url
full_url <- c()
for (i in 1:101) {
  full_url[i] <- paste0 ("https://en.wikipedia.org", url[i])
}

#remove empty first row
full_url <- full_url[-1]

```


b) Create a loop that uses your get_wiki_info function to import the information on political party and number of children for all members of the senate.

```{r}
#instantiate an empty vector
#install.packages('rlist')
library(rlist)

#instantiate empty 
senator_df <- list ()

for (i in 1: length(full_url)) {

 senator_df <- list.append(senator_df, get_wiki_info(full_url[i]))
 
}

senator_df
```

c) Clean up your data to provide some summary statistics. How many children does the average senator have? What about by party affiliation?

> The average kids that senators have is 2.797.
> 

```{r}
#instantiate a list to record children
child <- c()
party <- c()
for (i in 1:100) {
  child[i] <- senator_df[[i]]%>%
    filter(X1=='Children') %>%
    select(X2)
  
  party[i] <- senator_df[[i]]%>%
    filter(X1=='Political party') %>%
    select(X2)

}

str(child)

#cleaning the children list
#remove NA
child <- child %>%
  unlist () 

party <- party %>%
  unlist ()


#paste these two vectors together as a df
df <- cbind (child, party)
df <- as.data.frame(df)


## Calculate child summary
#remove any strings
child <- gsub("[a-zA-Z ]", "", df$child)
#remove other strings 
child <- gsub("[,]", "", child)
#remove NAs
child <- na.omit(child)
child
#remove irregular and empty
child <- child[-c(7, 25, 50, 36, 77)]
child
# Summary of senator's number of children
summary (as.numeric(child))

```




```{r, eval=FALSE}

#clean the data in party
party <- gsub("[/(*/)]", "", df$party)


df %>% 
  group_by(party) %>%
  summarize(means)




```

